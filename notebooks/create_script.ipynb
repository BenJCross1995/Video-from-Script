{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d39316",
   "metadata": {},
   "source": [
    "# Create Scripts from Wikipedia Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd02b7",
   "metadata": {},
   "source": [
    "The code below creates the scripts for the YouTube videos using the articles posted on the figures from Wikipedia.\n",
    "\n",
    "TO DO\n",
    "\n",
    "    * Add the date an article was generated. If it passes a certain threshold and a video is yet to be posted then we should really pull the data again or add a feature to check when the site was last updated and compare against that.\n",
    "    * Instead of using OpenAI use llama.cpp and an open sourced model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c662c",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "316ee2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import json\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "import urllib.parse\n",
    "import wikipedia\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from docx import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6abbbb",
   "metadata": {},
   "source": [
    "## Set OpenAI Key\n",
    "\n",
    "Set the OpenAI key from the credentials file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afb0fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = json.load(open(\"../Credentials.json\"))['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759ff35d-9ebc-4cd9-9532-0ffc2ea14b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def need_script(df_loc):\n",
    "\n",
    "    df = pd.read_excel(df_loc)\n",
    "\n",
    "    need_script = df[(df.Script_Created == \"No\")]\n",
    "\n",
    "    return need_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26042d27-8db9-46c3-bf6d-3b182468ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wikipedia_url(identifier):\n",
    "    # Decode the url\n",
    "    decoded_string = urllib.parse.unquote(identifier)\n",
    "    # Parse a wikipedia url to get the title\n",
    "    match = re.search(r'/([^/]+)$', decoded_string)\n",
    "    return match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd00725a-55e7-4027-8849-4a69fcf00480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(identifier):\n",
    "    # Get the title from the wiki URL\n",
    "    page_title = parse_wikipedia_url(identifier)\n",
    "    \n",
    "    # Get the page data and return the body text as context\n",
    "    page = wikipedia.page(title=page_title,\n",
    "                         auto_suggest=False,\n",
    "                          redirect=True)\n",
    "    context = page.content\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65aaf6a2-14ee-4dd9-adb6-a0dfc69c04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_prompt = \"\"\"\n",
    "    Please provide me with 10 very long and interesting facts about {figure} using only the context given below. \n",
    "    I have a youtube channel based on influential figures so this information must be accurate as my channel depends on it. \n",
    "    Please make each fact approximately 300 tokens long. DO NOT add additional text before the list of facts.\n",
    "    ----------\n",
    "    Context: ```{context}```\n",
    "    ----------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4a5f1dd-8a39-4613-8361-1e11a9c2a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_short_prompt = \"\"\"\n",
    "    Please provide me with 10 short but interesting facts about {figure} using only the context given below. \n",
    "    I have a youtube channel based on influential figures so this information must be accurate as my channel depends on it. \n",
    "    DO NOT add additional text before the list of facts.\n",
    "    ----------\n",
    "    Context: ```{context}```\n",
    "    ----------\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e976c2-a3e7-4b8e-8b58-0df6e2bdc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(llm_model=\"gpt-4o\", temperature=0.1, prompt=yt_prompt):\n",
    "    \n",
    "    model = ChatOpenAI(model=llm_model, temperature=temperature)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    chain = prompt | model | output_parser\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb0ff17-b7ba-4103-ae59-8be82348740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_script(figure, script_loc, df_loc,\n",
    "                   llm_model=\"gpt-4o\", temperature=0.1, prompt=yt_prompt):\n",
    "\n",
    "        df = pd.read_excel(df_loc)\n",
    "    \n",
    "        # Get the context from Wikipedia and run the chain\n",
    "        wiki_url = df.loc[(df.Name == figure),'Wikipedia'].values[0]\n",
    "        print(f\"Wikipedia URL: {wiki_url}\")\n",
    "    \n",
    "        context = get_context(wiki_url)\n",
    "\n",
    "        # Create the chain and invoke it\n",
    "        chain = create_chain(llm_model, temperature, prompt)\n",
    "        script = chain.invoke({\"figure\": figure, \"context\": context})\n",
    "\n",
    "        # Count the number of words in the paragraph\n",
    "        word_count = len(script.split())\n",
    "\n",
    "        # Print the figure's name and the word count\n",
    "        print(f\"{figure}: {word_count} Words\")\n",
    "        \n",
    "        # Create a new Document and add the created script then save as figure name\n",
    "        doc = Document()\n",
    "        doc.add_paragraph(script)\n",
    "        save_loc = script_loc + figure + \".docx\"\n",
    "        doc.save(save_loc)\n",
    "        \n",
    "        # Convert the No to Yes in needs audio column\n",
    "        df.loc[(df.Name == figure), \"Script_Created\"] = \"Yes\"\n",
    "        df.loc[(df.Name == figure), \"Word_Count\"] = word_count\n",
    "        df.loc[(df.Name == figure), \"Model_Used\"] = llm_model\n",
    "        \n",
    "        # Once all done stop the engine and then overwrite the Excel file\n",
    "        df.to_excel(df_loc, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“YouTube_Environment”",
   "language": "python",
   "name": "youtube_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
